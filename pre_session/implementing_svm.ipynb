{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3546492c",
   "metadata": {},
   "source": [
    "# Support Vector Machine (SVM) Implementation on Handwritten Digits Dataset\n",
    "\n",
    "This notebook demonstrates a self-driven analysis using Support Vector Machines (SVM) for classifying handwritten digits. The workflow includes data preprocessing, visualization, model training with different kernels, hyperparameter tuning, and robustness evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facf959b",
   "metadata": {},
   "source": [
    "### Import Required Libraries\n",
    "\n",
    "- **Import essential libraries** for data manipulation, visualization, and machine learning\n",
    "- These imports are foundational for all subsequent analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac96396",
   "metadata": {},
   "source": [
    "### Load and Prepare Dataset\n",
    "\n",
    "- **Load the digits dataset** from scikit-learn\n",
    "- **Extract features and labels** for modeling\n",
    "- This step sets up the data for further analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b68f9e1",
   "metadata": {},
   "source": [
    "### Data Preparation and Adding Noise\n",
    "\n",
    "- **Split the dataset** into training and test sets\n",
    "- **Add Gaussian noise** to 50% of the training data to test model robustness\n",
    "- Prepares data for evaluating SVM performance under noisy conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ca237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# Add noise to 50% of training data\n",
    "num_noisy = int(0.5 * len(X_train))\n",
    "indices = np.random.choice(len(X_train), num_noisy, replace=False)\n",
    "\n",
    "# Gaussian noise\n",
    "noise = np.random.normal(0, 8, size=X_train[indices].shape)\n",
    "X_train_noisy = X_train.copy()\n",
    "X_train_noisy[indices] += noise\n",
    "\n",
    "images = digits.images[y_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5520a047",
   "metadata": {},
   "source": [
    "### Visualize Sample Digits\n",
    "\n",
    "- **Display sample digit images** from the dataset\n",
    "- Provides visual context for the classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc9f20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i + 1)\n",
    "    plt.imshow(images[i], cmap='gray')\n",
    "    plt.title(f'Label: {y[i]}')\n",
    "    plt.axis('off')\n",
    "plt.suptitle(\"Sample Digits (0 to 4)\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a354d7e1",
   "metadata": {},
   "source": [
    "### Check Data Shapes\n",
    "\n",
    "- **Display the shapes** of training and test sets\n",
    "- Confirms the data split and readiness for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4678ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd01f7e",
   "metadata": {},
   "source": [
    "### PCA for Visualization\n",
    "\n",
    "- **Reduce data dimensionality** to 2 components using PCA\n",
    "- Facilitates visualization of class separation in 2D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e585cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f408c6",
   "metadata": {},
   "source": [
    "### Visualize PCA Projection\n",
    "\n",
    "- **Plot the 2D PCA projection** of the training data\n",
    "- Visualizes how well digit classes are separated after dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db73912",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y_train, palette='tab10', alpha=0.7, legend='full')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.title('PCA Projection of Digits 0-4')\n",
    "plt.legend(title=\"Digit Label\", bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858d740",
   "metadata": {},
   "source": [
    "### Train SVM with Linear Kernel\n",
    "\n",
    "- **Train a Support Vector Machine** with a linear kernel on noisy training data\n",
    "- **Evaluate accuracy** on the test set\n",
    "- Establishes a baseline for SVM performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8106891",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "svm_linear = SVC(kernel='linear', C=1.0)\n",
    "svm_linear.fit(X_train_noisy, y_train)\n",
    "y_pred_linear = svm_linear.predict(X_test)\n",
    "\n",
    "print(\"Linear SVM Accuracy:\", accuracy_score(y_test, y_pred_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3c371",
   "metadata": {},
   "source": [
    "### Standardize Features\n",
    "\n",
    "- **Standardize features** to zero mean and unit variance\n",
    "- Prepares data for SVMs with RBF or polynomial kernels\n",
    "- Improves model performance and stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4b281d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_noisy)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dfed93",
   "metadata": {},
   "source": [
    "### Train SVM with RBF Kernel\n",
    "\n",
    "- **Train an SVM** with an RBF (Radial Basis Function) kernel on standardized data\n",
    "- **Evaluate accuracy** on the test set\n",
    "- Compares performance with linear kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be56516",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_rbf = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svm_rbf.fit(X_train_scaled, y_train)\n",
    "y_pred_rbf = svm_rbf.predict(X_test_scaled)\n",
    "\n",
    "print(\"RBF SVM Accuracy:\", accuracy_score(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6f2064",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning with GridSearchCV\n",
    "\n",
    "- **Perform grid search** to find optimal SVM hyperparameters (kernel, C, gamma, degree)\n",
    "- **Train and evaluate** models using cross-validation\n",
    "- Identifies the best configuration for improved accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c3697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'C': [0.1, 1, 10],\n",
    "    'gamma': ['scale', 0.001, 0.01, 0.1],\n",
    "    'degree': [1,2,3,4, 5, 6]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=10)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291ed13",
   "metadata": {},
   "source": [
    "### Train SVM with Best Parameters\n",
    "\n",
    "- **Train an SVM** with the best parameters found from grid search\n",
    "- **Evaluate performance** on the test set\n",
    "- Demonstrates the impact of hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a47b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(C=1, degree=3, gamma=0.1, kernel='poly')\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "print(\"RBF SVM Accuracy:\", accuracy_score(y_test, y_pred_rbf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f826f4b",
   "metadata": {},
   "source": [
    "### Try Robust SVM Variants (NuSVC)\n",
    "\n",
    "- **Experiment with NuSVC**, a robust SVM variant\n",
    "- **Tune hyperparameters** using grid search\n",
    "- Compares alternative SVM formulations for potential performance gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a6bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "param_grid = { 'nu': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7],\n",
    "    'kernel': ['rbf', 'poly'],\n",
    "    'gamma': ['scale', 0.001, 0.01, 0.1],\n",
    "    'degree': [1,2,3,4, 5, 6]\n",
    "}\n",
    "\n",
    "grid =  GridSearchCV(NuSVC(random_state=42), param_grid=param_grid, cv=5, n_jobs=-1)\n",
    "grid.fit(X_train_scaled, y_train)\n",
    "print(\"Best Parameters:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002e1a9a",
   "metadata": {},
   "source": [
    "### Evaluate Best NuSVC Model\n",
    "\n",
    "- **Train and evaluate** the best NuSVC model found from grid search\n",
    "- **Report accuracy** on the test set\n",
    "- Assesses the effectiveness of robust SVM variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e73d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nusvc_best = grid.best_estimator_\n",
    "nusvc_best.fit(X_train_scaled, y_train)\n",
    "y_pred_nusvc = nusvc_best.predict(X_test_scaled)\n",
    "print(\"NuSVC Best Accuracy:\", accuracy_score(y_test, y_pred_nusvc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfd65a2",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "- **Summarize findings** from SVM experiments\n",
    "- Highlight the impact of noise, feature scaling, and hyperparameter tuning\n",
    "- Emphasize the importance of data quality for model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32011d6a",
   "metadata": {},
   "source": [
    "## Final Summary\n",
    "\n",
    "**Objective:**\n",
    "- Classify handwritten digits using Support Vector Machines (SVM) and analyze the impact of noise, feature scaling, and model tuning.\n",
    "\n",
    "**Steps Performed:**\n",
    "- Imported and explored the scikit-learn digits dataset.\n",
    "- Added Gaussian noise to training data to test model robustness.\n",
    "- Visualized data using PCA and sample digit images.\n",
    "- Trained SVM models with linear, RBF, and polynomial kernels.\n",
    "- Applied feature standardization and hyperparameter tuning with GridSearchCV.\n",
    "- Explored robust SVM variants (NuSVC) and compared their performance.\n",
    "\n",
    "**Key Results:**\n",
    "- Feature scaling and kernel choice significantly affected SVM performance.\n",
    "- Hyperparameter tuning improved accuracy, but noise limited maximum achievable performance.\n",
    "- NuSVC and other variants did not outperform standard SVM under noisy conditions.\n",
    "\n",
    "**Next Steps:**\n",
    "- Investigate advanced noise reduction or feature engineering techniques.\n",
    "- Explore ensemble methods or deep learning for further accuracy improvements.\n",
    "- Consider cross-validation for more robust model evaluation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
